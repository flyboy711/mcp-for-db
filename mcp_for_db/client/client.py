import json
import os
import asyncio
import sys
import time
from contextlib import AsyncExitStack
from enum import Enum
from pathlib import Path
from typing import Dict, List, Any, Optional

from dotenv import load_dotenv
from mcp import ClientSession, StdioServerParameters, stdio_client
from openai import OpenAI
from mcp_for_db import LOG_LEVEL
from mcp_for_db.debug.mcp_logger import MCPCommunicationLogger

from mcp_for_db.server.shared.utils import get_logger, configure_logger

sys.stdout.reconfigure(encoding='utf-8', errors='replace')
sys.stdin.reconfigure(encoding='utf-8', errors='replace')


class ModelProvider(Enum):
    """æ¨¡å‹æä¾›å•†æšä¸¾ï¼šå¯¹åº”ä¸åŒæä¾›å•†å¯èƒ½å¯¹åº”ä¸åŒçš„å®¢æˆ·ç«¯è°ƒç”¨æ–¹å¼"""
    OPENAI = "openai"
    QWEN_COMPATIBLE = "qwen_compatible"
    CUSTOM_OPENAI_COMPATIBLE = "custom_openai"


class OptimizedTaskProcessor:
    """ä¼˜åŒ–ä»»åŠ¡å¤„ç† - ä»…é€šè¿‡æç¤ºè¯æ¨¡æ¿è¿›è¡Œç¼–æ’"""

    def __init__(self, mcp_client):
        self.client = mcp_client
        self.logger = mcp_client.logger
        self.mcp_logger = mcp_client.mcp_logger

        # æç¤ºè¯æ¨¡æ¿æ˜ å°„
        self.prompt_templates = {
            "data_query": "query-table-data-prompt",
            "admin_task": "smart-tools-prompt"
        }

    async def process_query(self, user_query: str, conversation_history: List[Dict] = None) -> Dict[str, Any]:
        """å¤„ç†æŸ¥è¯¢ - ä»…ä½¿ç”¨æç¤ºè¯ä¼˜åŒ–"""
        start_time = time.time()
        self.mcp_logger.log_query_processing(user_query)

        try:
            # æ£€æŸ¥æ˜¯å¦éœ€è¦ç‰¹æ®Šæç¤ºè¯
            enhanced_prompt = await self._get_simple_prompt(user_query)

            # æ„å»ºæ¶ˆæ¯
            messages = conversation_history.copy() if conversation_history else []

            if enhanced_prompt:
                if not any(msg.get("role") == "system" for msg in messages):
                    messages.insert(0, {"role": "system", "content": enhanced_prompt})

            messages.append({"role": "user", "content": user_query})

            # æ‰§è¡ŒæŸ¥è¯¢ - ä½¿ç”¨æ‰€æœ‰å·¥å…·
            response = await self._execute_with_all_tools(messages)

            return {
                "success": True,
                "answer": response["answer"],
                "tool_calls": response.get("tool_calls", []),
                "messages": response["messages"],
                "optimization_used": bool(enhanced_prompt),
                "prompt_type": self._get_prompt_type(user_query) if enhanced_prompt else None,
                "tools_used": len(self.client.all_tools),
                "execution_time": time.time() - start_time
            }

        except Exception as e:
            self.logger.error(f"å¤„ç†æŸ¥è¯¢å¤±è´¥: {e}")
            # å›é€€åˆ°æ ‡å‡†å¤„ç†
            return await self._fallback_process(user_query, conversation_history)

    def _get_prompt_type(self, query: str) -> str:
        """ç¡®å®šæç¤ºè¯ç±»å‹"""
        query_lower = query.lower()

        if any(kw in query_lower for kw in ["æŸ¥è¯¢", "æ˜¾ç¤º", "è·å–", "æ•°æ®"]):
            return "data_query"
        elif any(kw in query_lower for kw in ["è¯Šæ–­", "ä¼˜åŒ–", "æ€§èƒ½", "åˆ†æ"]):
            return "admin_task"
        else:
            return "general"

    async def _get_simple_prompt(self, query: str) -> Optional[str]:
        """è·å–ç®€åŒ–æç¤ºè¯"""
        query_lower = query.lower()

        try:
            # æ•°æ®æŸ¥è¯¢ç±»ä»»åŠ¡
            if any(kw in query_lower for kw in ["æŸ¥è¯¢", "æ˜¾ç¤º", "è·å–", "æ•°æ®", "è¡¨", "å­—æ®µ"]):
                return await self.client.get_prompt("query-table-data-prompt", {"desc": query})

            # ç®¡ç†è¯Šæ–­ç±»ä»»åŠ¡
            elif any(kw in query_lower for kw in ["è¯Šæ–­", "ä¼˜åŒ–", "æ€§èƒ½", "åˆ†æ"]):
                return await self.client.get_prompt("smart-tools-prompt", {"task": query})

        except Exception as e:
            self.logger.debug(f"è·å–æç¤ºè¯å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å¤„ç†: {e}")

        return None

    async def _execute_with_all_tools(self, messages: List[Dict]) -> Dict[str, Any]:
        """ä½¿ç”¨æ‰€æœ‰å·¥å…·æ‰§è¡ŒæŸ¥è¯¢"""
        start_time = time.time()

        response = await self.client._chat_with_tools_direct(messages, self.client.all_tools)

        exec_time = time.time() - start_time
        self.mcp_logger.log_llm_interaction(
            model=self.client.model,
            messages=messages,
            response=response.get("answer", "")[:500],
            execution_time=exec_time
        )

        return response

    async def _fallback_process(self, user_query: str,
                                conversation_history: List[Dict] = None) -> Dict[str, Any]:
        """å›é€€å¤„ç†"""
        self.logger.info("ä½¿ç”¨å›é€€å¤„ç†æ¨¡å¼")
        return await self.client._process_query_standard(user_query, conversation_history)


class MCPClient:
    """MCP å®¢æˆ·ç«¯"""

    def __init__(self, servers_config: Dict[str, str] = None):
        self.logger = get_logger(__name__)
        self.logger.setLevel(LOG_LEVEL)
        configure_logger("mcp_client.log")

        self.logger.info("å¼€å§‹åˆå§‹åŒ– MCP å®¢æˆ·ç«¯...")
        self.mcp_logger = MCPCommunicationLogger()
        self.exit_stack = AsyncExitStack()

        # åŠ è½½é…ç½®
        load_dotenv(Path(__file__).parent.parent / "envs/.env")
        self.api_key = os.getenv("DASHSCOPE_API_KEY") or os.getenv("OPENAI_API_KEY")
        self.base_url = os.getenv("BASE_URL")
        self.model = os.getenv("MODEL", "qwen-plus")

        self.provider = self._detect_provider()

        if not self.api_key:
            raise ValueError("æœªæ‰¾åˆ°APIå¯†é’¥")

        self.client = self._initialize_client()

        # å­˜å‚¨ä¿¡æ¯
        self.sessions: Dict[str, ClientSession] = {}
        self.tools_by_session: Dict[str, list] = {}
        self.all_tools = []
        self.prompts_by_session: Dict[str, list] = {}
        self.all_prompts = []

        self.servers_config = servers_config or {
            "MySQLServer": "mcp_for_db.server.cli.mysql_cli",
            "DiFyServer": "mcp_for_db.server.cli.dify_cli",
        }

        self._is_initialized = False
        self.logger.info("MCPå®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")

    def _detect_provider(self) -> ModelProvider:
        model_lower = self.model.lower()
        if "qwen" in model_lower:
            return ModelProvider.QWEN_COMPATIBLE
        if self.base_url and "openai" not in self.base_url.lower():
            return ModelProvider.CUSTOM_OPENAI_COMPATIBLE
        return ModelProvider.OPENAI

    def _initialize_client(self):
        client_kwargs = {"api_key": self.api_key}

        if self.provider == ModelProvider.QWEN_COMPATIBLE:
            client_kwargs["base_url"] = self.base_url
        elif self.provider == ModelProvider.CUSTOM_OPENAI_COMPATIBLE:
            if self.base_url:
                client_kwargs["base_url"] = self.base_url
        else:
            if self.base_url and self.base_url != "https://dashscope.aliyuncs.com/compatible-mode/v1":
                client_kwargs["base_url"] = self.base_url

        return OpenAI(**client_kwargs)

    async def initialize(self):
        if self._is_initialized:
            return

        try:
            await self.connect_to_servers(self.servers_config)
            self._is_initialized = True
            self.logger.info("MCPæœåŠ¡åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            self.logger.error(f"MCPæœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    async def process_query(self, user_query: str,
                            conversation_history: List[Dict] = None,
                            use_optimization: bool = True) -> Dict[str, Any]:
        """å¤„ç†æŸ¥è¯¢ - ä½¿ç”¨ä¼˜åŒ–çš„å¤„ç†å™¨"""
        if not self._is_initialized:
            await self.initialize()

        if use_optimization:
            processor = OptimizedTaskProcessor(self)
            return await processor.process_query(user_query, conversation_history)
        else:
            return await self._process_query_standard(user_query, conversation_history)

    async def _chat_with_tools_direct(self, messages: List[Dict],
                                      tools: List[Dict]) -> Dict[str, Any]:
        """ç›´æ¥ä½¿ç”¨æŒ‡å®šå·¥å…·è¿›è¡Œå¯¹è¯"""
        tool_calls_info = []
        max_iterations = 5
        iteration = 0
        response = None

        while iteration < max_iterations:
            try:
                request_kwargs = {
                    "model": self.model,
                    "messages": messages,
                    "tools": tools
                }

                if self.provider == ModelProvider.QWEN_COMPATIBLE and "qwen3" in self.model.lower():
                    request_kwargs["extra_body"] = {"enable_thinking": False}

                response = self.client.chat.completions.create(**request_kwargs)

                if (hasattr(response.choices[0], 'finish_reason') and
                        response.choices[0].finish_reason == "tool_calls" and
                        hasattr(response.choices[0].message, 'tool_calls') and
                        response.choices[0].message.tool_calls):

                    messages, tool_call_info = await self._handle_tool_calls_openai(messages, response)
                    tool_calls_info.extend(tool_call_info)
                    iteration += 1
                else:
                    break

            except Exception as e:
                self.logger.error(f"APIè°ƒç”¨å¤±è´¥: {e}")
                if iteration == 0:  # ç¬¬ä¸€æ¬¡å¤±è´¥ï¼Œå°è¯•æ— å·¥å…·æ¨¡å¼
                    response = self.client.chat.completions.create(
                        model=self.model,
                        messages=messages
                    )
                    break
                else:
                    raise

        final_answer = ""
        if response and response.choices:
            final_answer = response.choices[0].message.content or "å¤„ç†å®Œæˆ"

        return {
            "answer": final_answer,
            "tool_calls": tool_calls_info,
            "messages": messages
        }

    async def connect_to_servers(self, servers: dict):
        successful_connections = 0

        for server_name, module_path in servers.items():
            try:
                start_time = time.time()
                session = await self._start_one_server(module_path)
                self.sessions[server_name] = session

                # è·å–å·¥å…·å’Œæç¤ºè¯
                resp = await session.list_tools()
                self.tools_by_session[server_name] = resp.tools

                try:
                    prompts_resp = await session.list_prompts()
                    self.prompts_by_session[server_name] = prompts_resp.prompts
                    self.all_prompts.extend(prompts_resp.prompts)
                except RuntimeError:
                    self.prompts_by_session[server_name] = []

                # å¤„ç†å·¥å…·å®šä¹‰
                for tool in resp.tools:
                    function_name = f"{server_name}_{tool.name}"
                    tool_definition = {
                        "type": "function",
                        "function": {
                            "name": function_name,
                            "description": tool.description or f"å·¥å…·: {tool.name}",
                            "parameters": self._convert_input_schema(tool.inputSchema)
                        }
                    }
                    self.all_tools.append(tool_definition)

                successful_connections += 1
                exec_time = time.time() - start_time
                self.logger.info(f"è¿æ¥ {server_name}: {len(resp.tools)}å·¥å…· ({exec_time:.1f}s)")

            except Exception as e:
                self.logger.error(f"è¿æ¥ {server_name} å¤±è´¥: {e}")
                continue

        if successful_connections == 0:
            raise Exception("æ²¡æœ‰æˆåŠŸè¿æ¥ä»»ä½•æœåŠ¡å™¨")

        self.logger.info(f"å·²è¿æ¥ {successful_connections} ä¸ªæœåŠ¡å™¨ï¼ŒåŠ è½½ {len(self.all_tools)} ä¸ªå·¥å…·")

    async def get_prompt(self, prompt_name: str, arguments: Dict[str, Any] = None) -> str:
        target_server = None
        target_prompt = None

        for server_name, prompts in self.prompts_by_session.items():
            for prompt in prompts:
                if prompt.name == prompt_name:
                    target_server = server_name
                    target_prompt = prompt
                    break
            if target_prompt:
                break

        if not target_prompt:
            raise Exception(f"æ‰¾ä¸åˆ°æç¤ºè¯: {prompt_name}")

        session = self.sessions[target_server]
        try:
            resp = await session.get_prompt(prompt_name, arguments or {})
            if hasattr(resp, 'messages') and resp.messages:
                content_parts = []
                for message in resp.messages:
                    if hasattr(message, 'content'):
                        if hasattr(message.content, 'text'):
                            content_parts.append(message.content.text)
                        elif isinstance(message.content, str):
                            content_parts.append(message.content)
                return "\n".join(content_parts)
            return "æç¤ºè¯æ‰§è¡ŒæˆåŠŸ"
        except Exception as e:
            raise Exception(f"è·å–æç¤ºè¯å¤±è´¥: {str(e)}")

    def _convert_input_schema(self, input_schema: Any) -> Dict:
        if not input_schema:
            return {"type": "object", "properties": {}, "required": []}

        if isinstance(input_schema, dict):
            return {
                "type": input_schema.get("type", "object"),
                "properties": input_schema.get("properties", {}),
                "required": input_schema.get("required", [])
            }

        try:
            if hasattr(input_schema, 'model_dump'):
                schema_dict = input_schema.model_dump()
            elif hasattr(input_schema, 'dict'):
                schema_dict = input_schema.dict()
            else:
                schema_dict = dict(input_schema)

            return {
                "type": schema_dict.get("type", "object"),
                "properties": schema_dict.get("properties", {}),
                "required": schema_dict.get("required", [])
            }
        except RuntimeError:
            return {"type": "object", "properties": {}, "required": []}

    async def _start_one_server(self, module_path: str) -> ClientSession:
        import sys
        env = os.environ.copy()
        env.update({
            "PYTHONPATH": str(Path(__file__).parent.parent.parent),
            "MCP_SERVER_MODE": "1"
        })

        server_params = StdioServerParameters(
            command=sys.executable,
            args=["-m", module_path],
            env=env
        )

        stdio_transport = await self.exit_stack.enter_async_context(
            stdio_client(server_params)
        )
        read_stream, write_stream = stdio_transport
        session = await self.exit_stack.enter_async_context(
            ClientSession(read_stream, write_stream)
        )

        await session.initialize()
        return session

    async def _process_query_standard(self, user_query: str,
                                      conversation_history: List[Dict] = None) -> Dict[str, Any]:
        # ä¿æŒåŸæœ‰é€»è¾‘
        messages = conversation_history.copy() if conversation_history else []
        messages.append({"role": "user", "content": user_query})

        try:
            response = await self._chat_with_tools_openai(messages)
            return {
                "success": True,
                "answer": response["answer"],
                "tool_calls": response.get("tool_calls", []),
                "messages": response["messages"],
                "optimization_used": False,
                "tools_used": len(self.all_tools)
            }
        except Exception:
            raise

    async def _chat_with_tools_openai(self, messages: List[Dict]) -> Dict[str, Any]:
        # ç›´æ¥ä½¿ç”¨ all_tools
        return await self._chat_with_tools_direct(messages, self.all_tools)

    async def _handle_tool_calls_openai(self, messages: List[Dict], response) -> tuple:
        tool_calls = response.choices[0].message.tool_calls
        assistant_message = {
            "role": "assistant",
            "content": response.choices[0].message.content,
            "tool_calls": []
        }

        for tool_call in tool_calls:
            assistant_message["tool_calls"].append({
                "id": tool_call.id,
                "type": "function",
                "function": {
                    "name": tool_call.function.name,
                    "arguments": tool_call.function.arguments
                }
            })

        messages.append(assistant_message)
        tool_calls_info = []

        for tool_call in tool_calls:
            tool_name = tool_call.function.name
            error = None
            start_time = time.time()

            try:
                tool_args = json.loads(tool_call.function.arguments)
            except json.JSONDecodeError as e:
                tool_args = {}
                error = f"å‚æ•°è§£æå¤±è´¥: {e}"

            tool_call_record = {
                "tool_name": tool_name,
                "arguments": tool_args,
                "call_id": tool_call.id
            }

            try:
                if not error:
                    result = await self.call_mcp_tool(tool_name, tool_args)
                    tool_call_record["result"] = result
                    tool_call_record["success"] = True
                else:
                    result = error
                    tool_call_record["result"] = result
                    tool_call_record["success"] = False
            except Exception as e:
                result = f"å·¥å…·è°ƒç”¨å¤±è´¥: {str(e)}"
                tool_call_record["result"] = result
                tool_call_record["success"] = False
                error = str(e)

            tool_calls_info.append(tool_call_record)

            messages.append({
                "role": "tool",
                "content": str(result),
                "tool_call_id": tool_call.id,
            })

            exec_time = time.time() - start_time
            self.mcp_logger.log_tool_call(
                server_name=tool_name.split("_")[0],
                tool_name=tool_name,
                arguments=tool_args,
                result=result[:500] if result else None,
                success=error is None,
                error=error,
                execution_time=exec_time
            )

        return messages, tool_calls_info

    async def call_mcp_tool(self, tool_full_name: str, tool_args: dict) -> str:
        parts = tool_full_name.split("_", 1)
        if len(parts) != 2:
            raise Exception(f"æ— æ•ˆçš„å·¥å…·åç§°æ ¼å¼: {tool_full_name}")

        server_name, tool_name = parts
        session = self.sessions.get(server_name)
        if not session:
            raise Exception(f"æ‰¾ä¸åˆ°æœåŠ¡å™¨: {server_name}")

        try:
            resp = await session.call_tool(tool_name, tool_args)

            if hasattr(resp, 'content'):
                if isinstance(resp.content, list):
                    return "\n".join(str(item) for item in resp.content if item)
                else:
                    return str(resp.content) if resp.content else "å·¥å…·æ‰§è¡ŒæˆåŠŸ"
            else:
                return "å·¥å…·æ‰§è¡ŒæˆåŠŸ"
        except Exception as e:
            raise Exception(f"è°ƒç”¨å·¥å…· {tool_name} å¤±è´¥: {str(e)}")

    async def cleanup(self):
        try:
            await self.exit_stack.aclose()
            self._is_initialized = False
            self.sessions.clear()
            self.tools_by_session.clear()
            self.all_tools.clear()
            self.prompts_by_session.clear()
            self.all_prompts.clear()
            self.logger.info("èµ„æºæ¸…ç†å®Œæˆ")
        except Exception as e:
            self.logger.error(f"æ¸…ç†èµ„æºå‡ºé”™: {e}")

    def get_available_tools(self) -> List[Dict]:
        return self.all_tools.copy()

    def get_available_prompts(self) -> List[Dict]:
        """è·å–å¯ç”¨æç¤ºè¯åˆ—è¡¨"""
        prompts_info = []
        for server_name, prompts in self.prompts_by_session.items():
            for prompt in prompts:
                prompt_info = {
                    "server": server_name,
                    "name": prompt.name,
                    "description": prompt.description or "æ— æè¿°",
                    "arguments": []
                }

                # å®‰å…¨å¤„ç†å‚æ•°
                if hasattr(prompt, 'arguments') and prompt.arguments:
                    try:
                        for arg in prompt.arguments:
                            if hasattr(arg, 'name'):
                                # PromptArgument å¯¹è±¡
                                arg_info = {
                                    "name": arg.name,
                                    "description": getattr(arg, 'description', ''),
                                    "required": getattr(arg, 'required', False)
                                }
                            elif hasattr(arg, 'dict'):
                                # Pydantic æ¨¡å‹
                                arg_dict = arg.dict()
                                arg_info = {
                                    "name": arg_dict.get('name', 'unknown'),
                                    "description": arg_dict.get('description', ''),
                                    "required": arg_dict.get('required', False)
                                }
                            elif isinstance(arg, dict):
                                # å­—å…¸å¯¹è±¡
                                arg_info = {
                                    "name": arg.get('name', 'unknown'),
                                    "description": arg.get('description', ''),
                                    "required": arg.get('required', False)
                                }
                            else:
                                # å…¶ä»–ç±»å‹ï¼Œè½¬ä¸ºå­—ç¬¦ä¸²
                                arg_info = {
                                    "name": str(arg),
                                    "description": '',
                                    "required": False
                                }
                            prompt_info["arguments"].append(arg_info)
                    except Exception as e:
                        self.logger.debug(f"å¤„ç†æç¤ºè¯ {prompt.name} å‚æ•°æ—¶å‡ºé”™: {e}")
                        prompt_info["arguments"] = []

                prompts_info.append(prompt_info)
        return prompts_info

    async def health_check(self) -> Dict[str, Any]:
        client_info = {
            "provider": self.provider.value,
            "model": self.model,
        }

        status = {
            "initialized": self._is_initialized,
            "provider": client_info["provider"],
            "model": client_info["model"],
            "servers": {},
            "total_tools": len(self.all_tools),
            "total_prompts": len(self.all_prompts)
        }

        for server_name, session in self.sessions.items():
            try:
                tools_resp = await session.list_tools()
                prompts_count = len(self.prompts_by_session.get(server_name, []))
                status["servers"][server_name] = {
                    "status": "healthy",
                    "tools_count": len(tools_resp.tools),
                    "prompts_count": prompts_count
                }
            except Exception as e:
                status["servers"][server_name] = {
                    "status": "error",
                    "error": str(e)
                }

        return status


async def main_test():
    print("å¯åŠ¨ MCP å®¢æˆ·ç«¯æµ‹è¯•...")
    client = MCPClient()

    try:
        await client.initialize()
        health = await client.health_check()
        print("å¥åº·æ£€æŸ¥:", json.dumps(health, indent=2, ensure_ascii=False))

        test_queries = [
            "æ˜¾ç¤ºå½“å‰æ•°æ®åº“çš„åŸºæœ¬ä¿¡æ¯",
            "æ˜¾ç¤ºæ‰€æœ‰æ•°æ®åº“è¡¨",
            "æŸ¥è¯¢ç”¨æˆ·è¡¨t_usersçš„ç»“æ„ä¿¡æ¯",
        ]

        for query in test_queries:
            print(f"\næŸ¥è¯¢: {query}")
            result = await client.process_query(query, use_optimization=True)
            if result["success"]:
                print(f"å›ç­”: {result['answer'][:200]}...")
                print(f"å·¥å…·: {result.get('tools_used', 0)}ä¸ª, è€—æ—¶: {result.get('execution_time', 0):.2f}s")
            else:
                print(f"é”™è¯¯: {result.get('error')}")
    finally:
        await client.cleanup()


async def main():
    import argparse
    import sys

    parser = argparse.ArgumentParser(description="MCP æ•°æ®åº“å®¢æˆ·ç«¯ (æ”¯æŒæ™ºèƒ½æç¤ºè¯ä¼˜åŒ–)")
    parser.add_argument("--query", nargs="?", help="è¦æ‰§è¡Œçš„æŸ¥è¯¢")
    parser.add_argument("--interactive", "-i", action="store_true", help="äº¤äº’æ¨¡å¼")
    parser.add_argument("--test", "-t", action="store_true", help="è¿è¡Œæµ‹è¯•")
    parser.add_argument("--no-optimize", action="store_true", help="ç¦ç”¨æ™ºèƒ½ä¼˜åŒ–")

    args = parser.parse_args()

    if args.test:
        await main_test()
        return

    client = MCPClient()

    try:
        print("è¿æ¥åˆ° MCP æœåŠ¡å™¨...")
        await client.initialize()
        print("è¿æ¥æˆåŠŸï¼\n")

        if args.interactive or not args.query:
            print("ğŸš€ MCP æ•°æ®åº“å®¢æˆ·ç«¯ - æ™ºèƒ½äº¤äº’æ¨¡å¼")
            print("=" * 50)
            print("å‘½ä»¤è¯´æ˜:")
            print("  quit/exit/q    - é€€å‡ºç¨‹åº")
            print("  help           - æŸ¥çœ‹å¯ç”¨å·¥å…·")
            print("  prompts        - æŸ¥çœ‹å¯ç”¨æç¤ºè¯")
            print("  health         - æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€")
            print("  opt on/off     - å¼€å¯/å…³é—­æ™ºèƒ½ä¼˜åŒ–")
            print("=" * 50)

            optimization_enabled = not args.no_optimize
            print(f"æ™ºèƒ½ä¼˜åŒ–: {'å¼€å¯' if optimization_enabled else 'å…³é—­'}")

            conversation_history = []

            while True:
                try:
                    query = input(f"\n{'ğŸ§ ' if optimization_enabled else 'ğŸ’»'} è¯·è¾“å…¥æ‚¨çš„é—®é¢˜: ").strip()
                    if not query:
                        continue

                    if query.lower() in ['quit', 'exit', 'q']:
                        break

                    # ä¿®å¤æç¤ºè¯æ˜¾ç¤ºé€»è¾‘
                    if query.lower() == 'prompts':
                        prompts = client.get_available_prompts()
                        print(f"\nå¯ç”¨æç¤ºè¯ ({len(prompts)} ä¸ª):")
                        for i, prompt in enumerate(prompts[:10], 1):
                            print(f"{i:2d}. {prompt['name']}")
                            desc = prompt['description']
                            print(f" æè¿°: {desc[:80]}{'...' if len(desc) > 80 else ''}")

                            # ä¿®å¤å‚æ•°å¤„ç†é€»è¾‘
                            if prompt.get('arguments'):
                                try:
                                    args_list = []
                                    for arg in prompt['arguments']:
                                        # å¤„ç† PromptArgument å¯¹è±¡
                                        if hasattr(arg, 'name'):
                                            arg_name = arg.name
                                        elif hasattr(arg, 'dict'):
                                            arg_dict = arg.dict()
                                            arg_name = arg_dict.get('name', 'unknown')
                                        elif isinstance(arg, dict):
                                            arg_name = arg.get('name', 'unknown')
                                        else:
                                            arg_name = str(arg)
                                        args_list.append(arg_name)

                                    if args_list:
                                        print(f" å‚æ•°: {', '.join(args_list)}")
                                except Exception as e:
                                    print(f" å‚æ•°: (è§£æå¤±è´¥: {e})")

                        if len(prompts) > 10:
                            print(f"\n... è¿˜æœ‰ {len(prompts) - 10} ä¸ªæç¤ºè¯")
                        continue

                    # å…¶ä»–å‘½ä»¤ä¿æŒä¸å˜...
                    if query.lower().startswith('opt '):
                        setting = query[4:].strip().lower()
                        if setting == 'on':
                            optimization_enabled = True
                            print("âœ… æ™ºèƒ½ä¼˜åŒ–å·²å¼€å¯")
                        elif setting == 'off':
                            optimization_enabled = False
                            print("âŒ æ™ºèƒ½ä¼˜åŒ–å·²å…³é—­")
                        else:
                            print("ç”¨æ³•: opt on/off")
                        continue

                    if query.lower() == 'help':
                        tools = client.get_available_tools()
                        print(f"\nå¯ç”¨å·¥å…· ({len(tools)} ä¸ª):")
                        for i, tool in enumerate(tools[:10], 1):
                            name = tool['function']['name']
                            desc = tool['function']['description']
                            print(f"{i:2d}. {name}")
                            print(f"    {desc[:80]}{'...' if len(desc) > 80 else ''}")
                        if len(tools) > 10:
                            print(f"\n... è¿˜æœ‰ {len(tools) - 10} ä¸ªå·¥å…·")
                        continue

                    if query.lower() == 'health':
                        health = await client.health_check()
                        print("\nç³»ç»ŸçŠ¶æ€:")
                        print(f"åˆå§‹åŒ–çŠ¶æ€: {'âœ…' if health['initialized'] else 'âŒ'}")
                        print(f"æ¨¡å‹æä¾›å•†: {health['provider']}")
                        print(f"ä½¿ç”¨æ¨¡å‹: {health['model']}")
                        print(f"æ€»å·¥å…·æ•°: {health['total_tools']}")
                        print(f"æ€»æç¤ºè¯æ•°: {health['total_prompts']}")
                        print("\næœåŠ¡å™¨çŠ¶æ€:")
                        for server_name, server_info in health['servers'].items():
                            status_icon = "âœ…" if server_info['status'] == 'healthy' else "âŒ"
                            print(
                                f"  {status_icon} {server_name}: {server_info.get('tools_count', 0)} å·¥å…·, {server_info.get('prompts_count', 0)} æç¤ºè¯")
                            if server_info['status'] != 'healthy':
                                print(f" é”™è¯¯: {server_info.get('error', 'æœªçŸ¥é”™è¯¯')}")
                        continue

                    if query.lower() in ['clear', 'cls']:
                        conversation_history = []
                        print("å¯¹è¯å†å²å·²æ¸…ç©º")
                        continue

                    if query.lower() == 'history':
                        print(f"\nå¯¹è¯å†å² ({len(conversation_history)} æ¡):")
                        for i, msg in enumerate(conversation_history[-10:], 1):
                            role_icon = "ğŸ¤–" if msg['role'] == 'assistant' else "ğŸ‘¤"
                            content = msg['content'][:100] + "..." if len(msg['content']) > 100 else msg['content']
                            print(f"{i:2d}. {role_icon} {msg['role']}: {content}")
                        if len(conversation_history) > 10:
                            print(f"\n... è¿˜æœ‰ {len(conversation_history) - 10} æ¡å†å²è®°å½•")
                        continue

                    # å¤„ç†æŸ¥è¯¢
                    print(f"ğŸ”„ å¤„ç†ä¸­... ({'ğŸ§ æ™ºèƒ½ä¼˜åŒ–' if optimization_enabled else 'ğŸ’» æ ‡å‡†æ¨¡å¼'})")
                    start_time = time.time()

                    result = await client.process_query(
                        query,
                        conversation_history=conversation_history.copy() if conversation_history else None,
                        use_optimization=optimization_enabled
                    )

                    if result["success"]:
                        print(f"\nå›ç­”:")
                        print(result['answer'])

                        # æ›´æ–°å¯¹è¯å†å²
                        conversation_history.append({"role": "user", "content": query})
                        conversation_history.append({"role": "assistant", "content": result['answer']})

                        # ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…
                        if len(conversation_history) > 20:
                            conversation_history = conversation_history[-20:]

                        # æ˜¾ç¤ºæ‰§è¡Œä¿¡æ¯
                        info_parts = []
                        if result.get("tool_calls"):
                            successful_calls = sum(1 for call in result["tool_calls"] if call.get("success", True))
                            info_parts.append(f"å·¥å…·è°ƒç”¨: {successful_calls}/{len(result['tool_calls'])}æ¬¡æˆåŠŸ")
                        if result.get("tools_used"):
                            info_parts.append(f"å¯ç”¨å·¥å…·: {result['tools_used']}ä¸ª")
                        if result.get("optimization_used"):
                            opt_type = result.get('prompt_type', 'unknown')
                            info_parts.append(f"ä¼˜åŒ–ç±»å‹: {opt_type}")

                        exec_time = result.get('execution_time', time.time() - start_time)
                        info_parts.append(f"è€—æ—¶: {exec_time:.2f}s")

                        if info_parts:
                            print(f"\næ‰§è¡Œä¿¡æ¯: {' | '.join(info_parts)}")

                        # æ˜¾ç¤ºå·¥å…·è°ƒç”¨è¯¦æƒ…
                        if result.get("tool_calls") and len(result["tool_calls"]) > 0:
                            print(f"\nğŸ”§ å·¥å…·è°ƒç”¨è¯¦æƒ…:")
                            for i, call in enumerate(result["tool_calls"], 1):
                                status_icon = "âœ…" if call.get("success", True) else "âŒ"
                                tool_name = call.get("tool_name", "unknown")
                                print(f"  {i}. {status_icon} {tool_name}")
                                if not call.get("success", True):
                                    result_preview = str(call.get("result", ""))[:100]
                                    print(f"     é”™è¯¯: {result_preview}...")
                    else:
                        print(f"\nâŒ é”™è¯¯: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")

                        conversation_history.append({"role": "user", "content": query})
                        conversation_history.append({
                            "role": "assistant",
                            "content": f"å¤„ç†å‡ºé”™: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"
                        })

                except KeyboardInterrupt:
                    print("\n\næ¥æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨é€€å‡º...")
                    break
                except Exception as e:
                    print(f"âŒ å¤„ç†é”™è¯¯: {e}")
                    import traceback
                    print(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")

        else:
            # å•æ¬¡æŸ¥è¯¢æ¨¡å¼
            optimization_enabled = not args.no_optimize
            print(f"ğŸ” å¤„ç†æŸ¥è¯¢: {args.query}")
            print(f"ğŸ§  æ™ºèƒ½ä¼˜åŒ–: {'å¼€å¯' if optimization_enabled else 'å…³é—­'}")

            start_time = time.time()
            result = await client.process_query(args.query, use_optimization=optimization_enabled)

            if result["success"]:
                print(f"\nğŸ’¡ å›ç­”:")
                print(result["answer"])

                exec_time = result.get('execution_time', time.time() - start_time)
                if result.get("optimization_used"):
                    opt_info = f"(ğŸ§  {result.get('prompt_type', 'unknown')}ä¼˜åŒ–, {exec_time:.2f}s)"
                    print(f"\n{opt_info}", file=sys.stderr)
                else:
                    print(f"\n(ğŸ’» æ ‡å‡†æ¨¡å¼, {exec_time:.2f}s)", file=sys.stderr)

                sys.exit(0)
            else:
                print(f"âŒ é”™è¯¯: {result.get('error', 'æœªçŸ¥é”™è¯¯')}", file=sys.stderr)
                sys.exit(1)

    except Exception as e:
        print(f"âŒ å¯åŠ¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    finally:
        print("\næ¸…ç†èµ„æº...")
        await client.cleanup()
        print("å†è§ï¼")


def cli_main():
    """CLIå…¥å£ç‚¹"""
    asyncio.run(main())


if __name__ == "__main__":
    # asyncio.run(main_test())
    cli_main()
